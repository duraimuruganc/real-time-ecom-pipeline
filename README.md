# Realâ€‘Timeâ€¯Eâ€‘commerceÂ AnalyticsÂ PipelineÂ ğŸš€

A handsâ€‘on demo that streams synthetic eâ€‘commerce events, lands them locally, loads them into **Snowflake** with Python, and surfaces KPIs.  
Perfect for showcasing **Snowflakeâ€¯Streamsâ€¯+â€¯Tasks, Arrowâ€‘based Python ETL, and (optional) Streamlit dashboards**â€”all on a tiny budget.

---

## âœ¨Â Key Components

| Layer                  | Tech & Files                                     | Highlights |
|------------------------|--------------------------------------------------|------------|
| **Data Generator**     | `data_generation/generate_events.py`             | 1â€¯msg/sec JSON (users & orders) |
| **Landing Zone**       | `landing/users/`, `landing/orders/` (local FS)   | Acts like a mini data lake; easy to swap for S3 |
| **ETL Loader**         | `etl/transform.py`, `etl/load_to_snowflake.py`   | Arrow upload, UTC session, microsecond precision |
| **StagingÂ +Â CDC**      | `RAW_*_STAGE` + `RAW_*_STREAM`                   | Streams capture inserts for incremental merges |
| **Starâ€‘Schema Tables** | `DIM_CUSTOMERS`, `FACT_ORDERS`                   | Filled via `ETL.MERGE_*` stored procs |
| **Orchestration**      | `TASK_MERGE_USERS`, `TASK_MERGE_ORDERS`          | Runs every minute *only when streams have data* |
| **Analytics Views**    | `VW_DAILY_REVENUE`, `VW_REPEAT_RATE`             | Daily revenue + repeatâ€‘customer % |
| **DashboardÂ (optional)** | `dashboard/app.py` (Streamlit)                 | Minuteâ€‘level revenue trend + KPI tiles |

---

## ğŸ—‚ï¸Â Project Structure

```
realâ€‘timeâ€‘ecomâ€‘pipeline/
â”œâ”€ data_generation/      # synthetic event producer
â”œâ”€ etl/                  # config, transforms, loader
â”œâ”€ sql/                  # DDL, streams, tasks, views
â”œâ”€ landing/              # JSON sink (autoâ€‘created)
â”œâ”€ dashboard/            # optional Streamlit UI
â”œâ”€ requirements.txt
â””â”€ README.md
```

---

## ğŸ’¸Â Cost Cheatâ€‘Sheet

| Item | Typical usage | $/month* |
|------|---------------|----------|
| Snowflake XS warehouse | 1â€¯creditâ€¯â‰ˆâ€¯$2â€“$3, ~5â€¯credits to demo | $10â€“$15 |
| Snowflake storage      | <Â 50â€¯MB | <Â $1 |
| Streamlit, dbtâ€¯Cloud   | Free tiers | $0 |

\*All within the $400 Snowflake free trial.

---

## âš¡Â QuickÂ Start

```bash
# 1. Clone & create virtualâ€‘env
git clone <yourâ€‘fork>
cd realâ€‘timeâ€‘ecomâ€‘pipeline
python -m venv .venv && source .venv/bin/activate   # Windows: .\.venv\Scriptsctivate
pip install -r requirements.txt

# 2. Add .env with Snowflake creds
cp .env.example .env  # or create manually; see below

# 3. Bootstrap schema & tasks
snowsql -f sql/create_schema.sql
snowsql -f sql/create_tasks.sql

# 4. Start pipeline
python data_generation/generate_events.py      # â© terminal 1
python etl/load_to_snowflake.py                # â© terminal 2

# 5. (Optional) dashboard
streamlit run dashboard/app.py
```

`.env` example:

```env
SNOWFLAKE_USER=YOUR_USER
SNOWFLAKE_PASSWORD=YOUR_PASSWORD
SNOWFLAKE_ACCOUNT=abcd-qn12345
SNOWFLAKE_WAREHOUSE=DEMO_WH
SNOWFLAKE_DATABASE=ECOM_DB
SNOWFLAKE_SCHEMA=PUBLIC
```

---

## ğŸ¾Â Verify It Works

```sql
-- New rows?
SELECT COUNT(*) FROM RAW_ORDERS_STAGE;

-- Revenue trend (last 60 minutes, minute grain)
SELECT DATE_TRUNC('minute', TS) AS MIN, SUM(AMOUNT)
FROM   FACT_ORDERS
WHERE  TS >= DATEADD(minute, -60, CURRENT_TIMESTAMP)
GROUP  BY 1 ORDER  BY 1;
```

---

---

## ğŸ“Â License

MIT â€” use, fork, and improve!
